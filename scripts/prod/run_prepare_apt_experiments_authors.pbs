#!/bin/bash -l
#PBS -l walltime=01:30:00,nodes=1:ppn=1,mem=22gb
#PBS -q lab
#PBS -o prepare_apt_experiments_authors.log
#PBS -m abe
#PBS -M smit7982@umn.edu
#PBS -N prepare_apt_experiments_authors
module unload python
module load python2/2.7.12_anaconda4.1.1
source ~/venv/bin/activate
cd ~/text-analysis/scripts/prod

data_dir=/home/srivbane/shared/caringbridge/data/lda_over_time/
input_file=clean_journals_hom_names.txt

# determine which sites should be in training and test sets
sort -n ${data_dir}${input_file} -t$'\t' -k1,4 -o ${data_dir}${input_file} -S 80% -T /home/srivbane/shared/caringbridge/data/tmp
input_files_keys=clean_journals_hom_names_keys.txt
python ${data_dir}journal_keys_and_counts.py --input_file ${data_dir}${input_file} --output_file ${data_dir}${input_files_keys}
R CMD BATCH --no-save --no-restore ${data_dir}train_test_for_authors.r ${data_dir}train_test_for_authors.Rout

# filter the journals to only include certain sites (those with x < num-posts < y, known HC)
# and split the journals into train and test files
train_keys=train_authors_keys.txt
test_keys=test_authors_keys.txt
train_lda=train_authors_lda.txt
test_lda=test_authors_lda.txt
sort -n ${data_dir}${train_keys} -t$'\t' -k1,4 -o ${data_dir}${train_keys} -S 80% -T /home/srivbane/shared/caringbridge/data/tmp
sort -n ${data_dir}${test_keys} -t$'\t' -k1,4 -o ${data_dir}${test_keys} -S 80% -T /home/srivbane/shared/caringbridge/data/tmp
python -m src.clean_journal.filter_train_test --data_dir ${data_dir} --input_file ${input_file} --train_keys ${train_keys} --test_keys ${test_keys} --train_out ${train_lda} --test_out ${test_lda} --method authors

# sort final results by time
sort -n ${data_dir}${train_lda} -t$'\t' -k4,4 -o ${data_dir}${train_lda} -S 80% -T /home/srivbane/shared/caringbridge/data/tmp
sort -n ${data_dir}${test_lda} -t$'\t' -k4,4 -o ${data_dir}${test_lda} -S 80% -T /home/srivbane/shared/caringbridge/data/tmp

# model params
vocab_size=5000
num_topics=50

# prepare LDA over time data
python -m src.topic_model.lda_over_time --train ${data_dir}${train_lda} --test ${data_dir}${test_lda} --train_bins ${data_dir}train-authors-seq.dat --test_bins ${data_dir}test-authors-seq.dat --data_dir ${data_dir} --keep_n ${vocab_size} --no_above 0.90 --num_topics ${num_topics} --log --data --rebuild

# prepare dtm data
dtm_home=/home/srivbane/smit7982/dtm/dtm/main
python -m src.topic_model.dtm --train_file ${data_dir}${train_lda} --test_file ${data_dir}${test_lda} --data_dir ${data_dir} --keep_n ${vocab_size} --num_topics ${num_topics} --dtm_binary ${dtm_home} --data

# prepare cdtm data for authors
train_cdtm_keys=train_authors_cdtm_keys.txt
test_cdtm_keys=test_authors_cdtm_keys.txt
cut -d$'\t' -f 1-4 ${data_dir}${train_lda} > ${data_dir}${train_cdtm_keys}
cut -d$'\t' -f 1-4 ${data_dir}${test_lda} > ${data_dir}${test_cdtm_keys}
train_cdtm=train_authors_cdtm.dat
test_cdtm=test_authors_cdtm.dat
python -m src.topic_model.build_cdtm_data --data_dir ${data_dir} --train_keys ${train_cdtm_keys} --test_keys ${test_cdtm_keys} --train_out ${train_cdtm} --test_out ${test_cdtm} --rounding_days 7

# prepare apt data
python -m src.topic_model.build_apt_data --data_dir ${data_dir} --train_cdtm ${train_cdtm} --test_cdtm ${test_cdtm} --train_keys ${train_cdtm_keys} --test_keys ${test_cdtm_keys}

